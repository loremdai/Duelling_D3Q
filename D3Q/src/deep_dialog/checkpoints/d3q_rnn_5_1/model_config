dict_path: ./deep_dialog/data/dicts.v3.p
movie_kb_path: ./deep_dialog/data/movie_kb.1k.p
act_set: ./deep_dialog/data/dia_acts.txt
slot_set: ./deep_dialog/data/slot_set.txt
goal_file_path: ./deep_dialog/data/user_goals_first_turn_template.part.movie.v1.p
diaact_nl_pairs: ./deep_dialog/data/dia_act_nl_pairs.v6.json
max_turn: 40
episodes: 500
slot_err_prob: 0.0
slot_err_mode: 0
intent_err_prob: 0.0
agt: 9
usr: 1
epsilon: 0.0
nlg_model_path: ./deep_dialog/models/nlg/lstm_tanh_relu_[1468202263.38]_2_0.610.p
nlu_model_path: ./deep_dialog/models/nlu/lstm_[1468447442.91]_39_80_0.921.p
act_level: 0
run_mode: 3
auto_suggest: 0
cmd_input_mode: 0
experience_replay_pool_size: 10000
dqn_hidden_size: 80
batch_size: 16
gamma: 0.9
predict_mode: False
simulation_epoch_size: 1
warm_start: 1
warm_start_epochs: 50
planning_steps: 4
trained_model_path: None
write_model_dir: ./deep_dialog/checkpoints/d3q_rnn_5_1
save_check_point: 10
success_rate_threshold: 0.6
split_fold: 5
learning_phase: all
grounded: False
boosted: 1
train_world_model: 1
save_model: 1
user_success_rate_threshold: 1
agent_success_rate_threshold: 1
pretrain_discriminator: 0
discriminator_nn_type: RNN
world_model_nn_type: MLP
train_discriminator: 1
model_type: D3Q
filter_experience_by_discriminator: 1
buffer_size_unit: 2000
num_exp_store_per_episode_unit: 10
domain_extension_exp: 0
planning_step_to_buffer: 1
